---
title: "Credit Card Fraud Detection"
author: "Pradeep Babburi"
date: "2/17/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(psych)
library(mvtnorm)
library(caret)
source('selectThreshold.R')
```
## 1. Introduction
Credit Card fraud identificatioin through anomaly detection algorithm using multivariate gaussian distribution. There are couple of reasons why I wanted to employ the anomaly detection algorithm over logistic regression or SVM. One, for the anomaly detection algorithm is well suited for highly skewed data like fraud detection and two that it is not biased towards posterior probabilites of the events. Another advantage is that it is relatively easy to train, infact there is not much training at all in an anomaly detection algorithm (other than finding the best epsilon). However, it has to be noted that for an anomaly detection to work well, we have to assume that the underlying features are independent. 

## 2. Get Dataset
Loading the credit card transactional data into the R environmet using "fread" from data.table library. The data has 28 variables/features which are the principal components of the original data. In addition, the data also contains Amount involved in the transaction, Time and the Class variables indicating if a transaction is fraud (positive case = 1) or not (negative case = 0). 
```{r read data, echo=TRUE}
X <- fread(input = "creditcard.csv", sep = ",", header = T, showProgress = T)
X <- data.frame(X)
colnames(X)
mA <- sum(as.numeric(X$Class))/nrow(X)
mA*100
```

It is evident that the data is highly skewed with only less than 0.2% of the transactions being fraud and the rest being legitimate. To do some exploratory analysis let us separate the normal and anomalous examples and find out how the features differ between the two datasets.

```{r separate data, echo=TRUE}
rownames(X) <- 1:nrow(X)
Xgood <- X[X$Class == 0,]
Xanom <- X[X$Class == 1,]
```

## 3. Exploratory Analysis
As an initial let's find the mean values of all the features for both normal and anomalous examples and see how they vary. 

```{r finding means, echo=TRUE}
mugood <- apply(Xgood[sample(rownames(Xgood), size = as.integer(mA*nrow(X)), replace = F), -c(1, 30, 31)], 2, mean)
muanom <- apply(Xanom[, -c(1, 30, 31)], 2, mean)
plot(muanom, col = "blue", xlab = "Features", ylab = "Mean")
lines(muanom, col = "blue", lwd = 2)
points(mugood, col = "black")
lines(mugood, col = "black", lwd = 2)
legend("topright", legend = c("Good", "Anomalous"), lty = c(1,1), col = c("black", "blue"), lwd = c(2,2))
```

It is obvious that the mean value of some of the features for anomalous examples fall out of range. However, some features especially the later ones (19 through 28) does not vary as much. Hence, for our model it might be safe for us to just ignore these features and focus on those that contribute significantly for a transaction to be identified as fraud. We can also plot the variance of our features in a similar way, however for now I am going to assume that the variance is in its decreasing order from the first feature to the last as these are just the first few orthonormal vectors resulting from PCA of the original data.

## 4. Feature Engineering

Incidentally, let's ignore the features that aren't of much interest and simplify the dataset for further analysis and training. 
```{r features, echo=TRUE}
# drop features that are trivial
todrop <- paste("V", c(8, 13, 15, 19:28), sep = "")
Xgood[, todrop] <- NULL
Xanom[, todrop] <- NULL
# transform the features into more gaussian like
#Xgood[,-c(1,17,18)] <- log(Xgood[,-c(1,17,18)] + 200)
#Xanom[,-c(1,17,18)] <- log(Xanom[,-c(1,17,18)] + 200)
# plot the histogram of features
multi.hist(Xgood[,c(2,3,5,9)], density = T)
```

Next, split the data into training, cross validation and test sets. We will esimate the mean and covariance using the training set, find the best epsilon using the cross validation set and evaluate model performance using the test set. We are going to put 60% of the normal examples into training, 20% into cross validation and the remaining 20% into test set with no anomalous examples in the training set and 50% in each of cross validation and test sets. The reason for this is that we want to estimate the gaussian from only the good transactions and try to find a threshold  (epsilon) that separates the anomalous examples using the cross validation set.

```{r split data, echo=TRUE}
g <- nrow(Xgood); a <- nrow(Xanom)
rg <- sample(1:g, g, replace = F)
ra <- sample(1:a, a, replace = F)
# split the data 60/20/20 into train/cv/test set with 0/50/50 anomalous examples 
# training set
Xtrain <- data.matrix(Xgood[rg[1:(g*0.6)],-c(1,17)])
# cross validation set
Xcv <- data.matrix(rbind(Xgood[rg[(g*0.6+1):(g*0.8)],-c(1,17)], Xanom[ra[1:(a*0.5)],-c(1,17)]))
# shuffle the data
Xcv <- Xcv[sample(nrow(Xcv), nrow(Xcv), replace = F),]
# test set
Xtest <- data.matrix(rbind(Xgood[rg[(g*0.8+1):g],-c(1,17)], Xanom[ra[(a*0.5 + 1):a],-c(1,17)]))
Xtest <- Xcv[sample(nrow(Xtest), nrow(Xtest), replace = F),]
# cleanup variables that are not required
rm(list = c("a", "g", "ra", "rg", "todrop"))
```

## 5. Model Formulation
Estimating the mean and covariance of the training set.

```{r estimate parameters, echo=TRUE}
mu <- apply(Xtrain[,-16], 2, mean)       # mean of all features
sigma <- cov(Xtrain[,-16])               # covariance matrix of all features
#sigma <- apply(Xtrain[,-16], 2, var)    
#sigma <- diag(sigma)                      # assuming all the features are uncorrelated
```

Calculating the pdf of all examples in the cross validation set using the mean and covariance from the training set. The function selectThreshold takes the ground truth positive and negative examples and the calculated probabilities to find the optimum threshold value. 

```{r indepenence assumption, echo=TRUE}
pcv <- dmvnorm(Xcv[,-16], mu, sigma)
epsilon <- selectThreshold(Xcv[,16], pcv)
sprintf('The threshold value is found to be epsilon = %e', epsilon)
```

## 6. Model Evaluation

Let's test the model performance using the test set by calculating the pdfs the same way as we did for the cross validation set. Consequently, predicting the positive class whenever the estimated probability is less than the threshold value and negative otherwise.

```{r testing, echo=TRUE}
ptest <- dmvnorm(Xtest[,-16], mu, sigma)
prediction <- as.numeric(ptest < epsilon)
confusionMatrix(table(Xtest[,16], prediction), positive = levels(factor(Xtest[,16]))[2])
```

As we can see that the model predicted a positive prediction rate of about 87% and negative prediction rate of 95% where the positive class being a fraudlent transaction. 

## 7. Conclusion

## 8. Next Steps
